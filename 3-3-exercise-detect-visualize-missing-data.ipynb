{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise: Titanic Dataset - Find and Visualize Missing Data\n",
        "\n",
        "Datasets can often have missing data, which can cause problems when we perform machine learning. Missing data can be hard to spot at a first glance.\n",
        "\n",
        "Our scenario uses a list of passengers on the failed maiden voyage of the Titanic. We want to know which factors predicted passenger survival. For our first task, which we perform here, we check whether our dataset has missing information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## The required 'matplotlib' visualization library\n",
        "\n",
        "This tutorial relies on the 'matplotlib' Python visualization library to build data graph resources. Depending on the \n",
        "environment you use to execute the code in this notebook, you might need to install that library to proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Preparing data\n",
        "\n",
        "Let's use Pandas to load the dataset and take a cursory look at it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677282976719
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: missingno in c:\\users\\maeud\\anaconda3\\lib\\site-packages (0.5.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from missingno) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from missingno) (3.8.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from missingno) (1.11.4)\n",
            "Requirement already satisfied: seaborn in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from missingno) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.2)\n",
            "Requirement already satisfied: pandas>=0.25 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from seaborn->missingno) (2.1.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\maeud\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'titanic.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/titanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Let's take a look at the data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead()\n",
            "File \u001b[1;32mc:\\Users\\maeud\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\maeud\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\maeud\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[1;32mc:\\Users\\maeud\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\maeud\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install missingno\n",
        "\n",
        "# Load data from our dataset file into a pandas dataframe\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/titanic.csv\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
        "dataset = pd.read_csv('titanic.csv', index_col=False, sep=\",\", header=0)\n",
        "\n",
        "# Let's take a look at the data\n",
        "dataset.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll see the number of samples and columns in the data set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677282985793
        }
      },
      "outputs": [],
      "source": [
        "# Shape tells us how many rows and columns we have\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have data for 891 passengers, each described by 12 different variables.\n",
        "\n",
        "## Finding Missing Data\n",
        "\n",
        "Do we have a complete dataset?\n",
        "\n",
        "No. We know from historical records that there were more than 2000 people on the Titanic, so we are clearly missing information on more than 1000 people! \n",
        "\n",
        "How can we tell if the available data is complete?\n",
        "\n",
        "We could print the entire dataset, but this might involve human error, and it would become impractical with this many samples.\n",
        "\n",
        "A better option would use `pandas` to report the columns that have \"empty\" cells:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677282996252
        }
      },
      "outputs": [],
      "source": [
        "# Calculate the number of empty cells in each column\n",
        "# The following line consists of three commands. Try\n",
        "# to think about how they work together to calculate\n",
        "# the number of missing entries per column\n",
        "missing_data = dataset.isnull().sum().to_frame()\n",
        "\n",
        "# Rename column holding the sums\n",
        "missing_data = missing_data.rename(columns={0:'Empty Cells'})\n",
        "\n",
        "# Print the results\n",
        "print(missing_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like we don't know the age of 177 passengers, and we don't know if two passengers even embarked.\n",
        "\n",
        "Cabin information for a whopping 687 persons is also missing.\n",
        "\n",
        "## Missing Data Visualizations\n",
        "\n",
        "It can sometimes help if we can find some kind of pattern in the missing data.   \n",
        "\n",
        "We can plot the absence of data in a few ways. One of the most helpful is to literally plot gaps in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677283003579
        }
      },
      "outputs": [],
      "source": [
        "import missingno as msno\n",
        "\n",
        "# Plot a matrix chart, set chart and font size\n",
        "msno.matrix(dataset, figsize=(10,5), fontsize=11)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The horizontal white bars in the graph show missing data. Here, the patterns aren't visually clear, but maybe many passengers with missing `Age` information are also missing `Cabin` information.\n",
        "\n",
        "## Identifying Individual Passengers with Missing Information.\n",
        "\n",
        "Let's use pandas to get a list of passengers of unknown age:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677283010269
        }
      },
      "outputs": [],
      "source": [
        "# Select Passengers with unknown age\n",
        "# Notice how we use .isnull() rows with no value\n",
        "unknown_age = dataset[dataset[\"Age\"].isnull()]\n",
        "\n",
        "# Print only the columns we want for the moment (to better fit the screen)\n",
        "# limit output to 20 rows\n",
        "unknown_age[[\"PassengerId\",\"Name\", \"Survived\", \"Age\"]][:20]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This technique lists the passengers with missing `Cabin` or `Embarked` information as well. Let's combine these using an `AND`, to see how many passengers are missing both Cabin and Age information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677283016339
        }
      },
      "outputs": [],
      "source": [
        "# Find those passengers with missing age or cabin information\n",
        "missing_age = dataset[\"Age\"].isnull()\n",
        "missing_cabin = dataset[\"Cabin\"].isnull()\n",
        "\n",
        "# Find those passengers missing both\n",
        "unknown_age_and_cabin = dataset[missing_age & missing_cabin]\n",
        "print(\"Number of passengers missing age and cabin information:\", len(unknown_age_and_cabin))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our suspicions were correct - most passengers missing age information are also missing cabin information. \n",
        "\n",
        "Normally, from here, we would want to know _why_ we have this issue. A good hypothesis is that information was not collected carefully enough for the passengers who used the cheap tickets. \n",
        "\n",
        "Let's plot a histogram of ticket classes, and another of just people missing information. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677283029277
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist((dataset.values[:,2]),bins=[0.5, 1.5, 2.5, 3.5],edgecolor=\"white\")\n",
        "plt.hist((unknown_age_and_cabin.values[:,2]),bins=[0.5, 1.5, 2.5, 3.5],edgecolor=\"white\")\n",
        "plt.xticks([1, 2, 3])\n",
        "plt.xlabel(\"Pclass (Passenger Class)\", fontsize=16)\n",
        "plt.ylabel(\"Passenger Count\", fontsize=16)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that those passengers with missing information typically used the cheaper tickets. These sorts of biases might cause problems in real-world analyses.\n",
        "\n",
        "## Missing as Zero\n",
        "\n",
        "Additionally, some datasets may have missing values that appear as zero. While the Titanic dataset doesn't have this problem, let's see how that would work here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677284001038
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print out the average age of passengers for whom we have age data\n",
        "mean_age = np.mean(dataset.Age)\n",
        "print(\"The average age on the ship was\", mean_age, \"years old\")\n",
        "\n",
        "# Now, make another model where missing ages contained a '0'\n",
        "dataset['Age_2'] = dataset['Age'].fillna(0)\n",
        "mean_age = np.mean(dataset.Age_2)\n",
        "print(\"The average age on the ship was\", mean_age, \"years old\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What happened here? Our analyses consider the values of `0` not as 'missing' values, but instead as actual age values.\n",
        "\n",
        "This shows that it can be important to time the review of your raw data before you run the analyses. Another fast way to get a feel for a dataset is to graph its distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677284008964
        }
      },
      "outputs": [],
      "source": [
        "plt.hist(dataset[\"Age\"],bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90],edgecolor=\"white\")\n",
        "plt.xticks([0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "plt.xlim([0, 90])\n",
        "plt.xlabel(\"Age_2\", fontsize=16)\n",
        "plt.ylabel(\"Passenger Count\", fontsize=16)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we see an unlikely number of very young children. This would be cause for further inspection of the data, to hopefully spot the fact that the missing ages appear as zeros.\n",
        "\n",
        "## Handling Missing Data\n",
        "\n",
        "We have many ways to address missing data, each with pros and cons.\n",
        "\n",
        "Let's take a look at the less complex options:\n",
        "\n",
        "### Option 1: Delete data with missing rows\n",
        "\n",
        "For a model that cannot handle missing data, the most prudent thing to do is to remove rows that have information missing.\n",
        "\n",
        "Let's remove some data from the `Embarked` column, which only has two rows with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677284015800
        }
      },
      "outputs": [],
      "source": [
        "# Create a \"clean\" dataset, where we cumulatively fix missing values\n",
        "# Start by removing rows ONLY where \"Embarked\" has no values\n",
        "print(f\"The original size of our dataset was\", dataset.shape)\n",
        "clean_dataset = dataset.dropna(subset=[\"Embarked\"])\n",
        "clean_dataset = clean_dataset.reindex()\n",
        "\n",
        "# How many rows do we have now?\n",
        "print(\"The shape for the clean dataset is\", clean_dataset.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that this removed the offending two rows from our new, clean dataset.\n",
        "\n",
        "### Option 2: Replace empty values with the mean or median for that data.\n",
        "\n",
        "Sometimes, our model cannot handle missing values, and we also cannot afford to remove too much data. In this case, we can sometimes fill in missing data with an average calculated on the basis of the rest of the dataset. Note that imputing data like this can affect model performance in a negative way. Usually, it's better to simply remove missing data, or to use a model designed to handle missing values.\n",
        "\n",
        "Here, we impute data for the `Age` field. We use the mean `Age` from the remaining rows, given that >80% of these have values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677284021762
        }
      },
      "outputs": [],
      "source": [
        "# Calculate the mean value for the Age column\n",
        "mean_age = clean_dataset[\"Age\"].mean()\n",
        "\n",
        "print(\"The mean age is\", mean_age)\n",
        "\n",
        "# Replace empty values in \"Age\" with the mean calculated above\n",
        "clean_dataset[\"Age\"].fillna(mean_age, inplace=True)\n",
        "\n",
        "# Let's see what the clean dataset looks like now\n",
        "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Age` field has no longer has empty cells.\n",
        "\n",
        "### Option 3: Assign a new category to unknown categorical data\n",
        "\n",
        "The `Cabin` field is a categorical field, because the Titanic cabins have a finite number of possible options. Unfortunately, many records have no cabin listed.\n",
        "\n",
        "For this exercise, it makes perfect sense to create an `Unknown` category, and assign it to the cases where the cabin is unknown:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677284026121
        }
      },
      "outputs": [],
      "source": [
        "# Assign unknown to records where \"Cabin\" is empty\n",
        "clean_dataset[\"Cabin\"].fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# Let's see what the clean dataset looks like now\n",
        "print(clean_dataset.isnull().sum().to_frame().rename(columns={0:'Empty Cells'}))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it! No more missing data!\n",
        "\n",
        "We only lost two records (where `Embarked` was empty).\n",
        "\n",
        "That said, we had to make some approximations to fill the missing gaps for the `Age` and `Cabin` columns, and those will certainly influence the performance of any model we train on this data.\n",
        "\n",
        "## Summary\n",
        "\n",
        "Missing values can affect the way a Machine Learning model works in a negative way. It's important to quickly verify the existence of data gaps, and the locations of those gaps.\n",
        "\n",
        "You can now get a \"big picture\" of what is missing. Using lists and charts, you can select only those items that you must address.\n",
        "\n",
        "In this exercise, we practiced:\n",
        "\n",
        "- Finding and visualization of missing dataset values, with the `pandas` and `missingno` packages.\n",
        "- Checking whether a dataset uses the value '0' to represent missing values.\n",
        "- Handling missing data in three ways: removal of rows that contain missing values, replacement of the missing values with the mean or median of that particular feature, and creation of a new `Unknown` category, when dealing with categorical data."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d986dcce87f8efbe64f9555c9767535f3ea76b09442c50f327a793e0b4903fbe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
